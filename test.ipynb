{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This integrated process ensures that the video output from Wav2Lip undergoes high-quality enhancement for both the overall resolution (via RealESRGAN) and facial details (via GFPGAN). Finally, it reassembles the video with the enhanced frames and the original synced audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code for recording audio\n",
    "from IPython.display import HTML, Audio\n",
    "from base64 import b64decode\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read as wav_read\n",
    "import io\n",
    "import ffmpeg\n",
    "from IPython.display import clear_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Create the temp directory if it doesn't exist\n",
    "temp_dir = \"temp\"\n",
    "os.makedirs(temp_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Have a good GPU Skip this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def get_video_duration(video_path):\n",
    "    \"\"\"Returns the duration of the video in seconds.\"\"\"\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    duration = frame_count / fps\n",
    "    video.release()\n",
    "    return duration\n",
    "\n",
    "def trim_video_to_5_seconds(input_video_path, output_video_path):\n",
    "    \"\"\"Trims the video to the first 5 seconds if it is longer than 5 seconds.\"\"\"\n",
    "    duration = get_video_duration(input_video_path)\n",
    "    if duration <= 5:\n",
    "        print(f\"Video is already {duration:.2f} seconds long. No trimming needed.\")\n",
    "        return\n",
    "    \n",
    "    command = [\n",
    "        \"ffmpeg\", \n",
    "        \"-i\", input_video_path,   # Input file\n",
    "        \"-t\", \"5\",                # Duration to keep (5 seconds)\n",
    "        \"-c\", \"copy\",             # Copy codec (no re-encoding)\n",
    "        output_video_path         # Output file\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        subprocess.run(command, check=True)\n",
    "        print(f\"Video trimmed to 5 seconds and saved as: {output_video_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error trimming video: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m input_video \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMonnaLisa.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m output_video \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrimmed_video_5s.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mtrim_video_to_5_seconds\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_video\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 16\u001b[0m, in \u001b[0;36mtrim_video_to_5_seconds\u001b[1;34m(input_video_path, output_video_path)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrim_video_to_5_seconds\u001b[39m(input_video_path, output_video_path):\n\u001b[0;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Trims the video to the first 5 seconds if it is longer than 5 seconds.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     duration \u001b[38;5;241m=\u001b[39m \u001b[43mget_video_duration\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_video_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m duration \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m:\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideo is already \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds long. No trimming needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[26], line 10\u001b[0m, in \u001b[0;36mget_video_duration\u001b[1;34m(video_path)\u001b[0m\n\u001b[0;32m      8\u001b[0m fps \u001b[38;5;241m=\u001b[39m video\u001b[38;5;241m.\u001b[39mget(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_FPS)\n\u001b[0;32m      9\u001b[0m frame_count \u001b[38;5;241m=\u001b[39m video\u001b[38;5;241m.\u001b[39mget(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_FRAME_COUNT)\n\u001b[1;32m---> 10\u001b[0m duration \u001b[38;5;241m=\u001b[39m \u001b[43mframe_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\n\u001b[0;32m     11\u001b[0m video\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m duration\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_video = \"MonnaLisa.mp4\"\n",
    "output_video = \"trimmed_video_5s.mp4\"\n",
    "trim_video_to_5_seconds(input_video, output_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file successfully\n",
      "Video path: input_video.mp4\n",
      "Video resolution: (360, 288)\n",
      "No resizing needed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "import moviepy.editor as mp\n",
    "import time\n",
    "import tempfile\n",
    "\n",
    "def get_video_resolution(video_path):\n",
    "    \"\"\"Function to get the resolution of a video\"\"\"\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    video.release()\n",
    "    return (width, height)\n",
    "\n",
    "def resize_video(video_path, new_resolution):\n",
    "    \"\"\"Function to resize a video and handle file replacement\"\"\"\n",
    "    temp_dir = tempfile.mkdtemp()  # Create a temporary directory\n",
    "    temp_path = os.path.join(temp_dir, \"temp_resized_video.mp4\")\n",
    "    backup_path = video_path + \".bak\"  # Backup path for original file\n",
    "    \n",
    "    try:\n",
    "        # Open the original video\n",
    "        video = cv2.VideoCapture(video_path)\n",
    "        if not video.isOpened():\n",
    "            print(f\"Error opening video file: {video_path}\")\n",
    "            return None\n",
    "        \n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for mp4 files\n",
    "        fps = video.get(cv2.CAP_PROP_FPS)\n",
    "        width, height = new_resolution\n",
    "        writer = cv2.VideoWriter(temp_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        while True:\n",
    "            success, frame = video.read()\n",
    "            if not success:\n",
    "                break\n",
    "            resized_frame = cv2.resize(frame, (width, height))\n",
    "            writer.write(resized_frame)\n",
    "        \n",
    "        video.release()\n",
    "        writer.release()\n",
    "        \n",
    "        # Try to rename the original file\n",
    "        for attempt in range(5):  # Retry up to 5 times\n",
    "            try:\n",
    "                if os.path.exists(backup_path):\n",
    "                    os.remove(backup_path)  # Ensure backup file is not present\n",
    "                os.rename(video_path, backup_path)\n",
    "                break\n",
    "            except PermissionError as e:\n",
    "                print(f\"Attempt {attempt+1}: Unable to rename the original file '{video_path}'. Error: {e}\")\n",
    "                time.sleep(1)  # Wait a moment before retrying\n",
    "        \n",
    "        # Replace the original file with the resized video\n",
    "        try:\n",
    "            shutil.move(temp_path, video_path)\n",
    "        except PermissionError as e:\n",
    "            print(f\"Unable to replace the original file '{video_path}' with the resized video. Error: {e}\")\n",
    "            return None\n",
    "        \n",
    "        # Clean up temporary directory\n",
    "        shutil.rmtree(temp_dir)\n",
    "        \n",
    "        return video_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error during video processing: {e}\")\n",
    "        return None\n",
    "\n",
    "# File upload widget\n",
    "upload_widget = widgets.FileUpload(accept='.mp4', multiple=False)\n",
    "\n",
    "def on_upload_change(change):\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    if upload_widget.value:\n",
    "        # Handle the uploaded file\n",
    "        file_info = upload_widget.value[0]\n",
    "        file_content = file_info['content']\n",
    "        with open('input_video.mp4', 'wb') as f:\n",
    "            f.write(file_content)\n",
    "        print('Uploaded file successfully')\n",
    "        \n",
    "        # Define the video path\n",
    "        PATH_TO_YOUR_VIDEO = 'input_video.mp4'\n",
    "        print(f\"Video path: {PATH_TO_YOUR_VIDEO}\")  # Debug print\n",
    "        \n",
    "        # Check video duration\n",
    "        video_duration = mp.VideoFileClip(PATH_TO_YOUR_VIDEO).duration\n",
    "        if video_duration > 60:\n",
    "            print(\"WARNING: Video duration exceeds 60 seconds. Please upload a shorter video.\")\n",
    "            return\n",
    "        \n",
    "        # Check video resolution and resize if necessary\n",
    "        video_resolution = get_video_resolution(PATH_TO_YOUR_VIDEO)\n",
    "        print(f\"Video resolution: {video_resolution}\")  # Debug print\n",
    "        if video_resolution[0] >= 1920 or video_resolution[1] >= 1080:\n",
    "            print(\"Resizing video to 720p...\")\n",
    "            PATH_TO_YOUR_VIDEO = resize_video(PATH_TO_YOUR_VIDEO, (1280, 720))\n",
    "            if PATH_TO_YOUR_VIDEO:\n",
    "                print(\"Video resized to 720p\")\n",
    "            else:\n",
    "                print(\"Error resizing video\")\n",
    "        else:\n",
    "            print(\"No resizing needed\")\n",
    "\n",
    "upload_widget.observe(on_upload_change, names='value')\n",
    "\n",
    "# Display the file upload widget\n",
    "display(upload_widget)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Audio or Wana write your self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, Audio\n",
    "from gtts import gTTS\n",
    "\n",
    "# Create the widgets\n",
    "audio_source = widgets.RadioButtons(\n",
    "    options=['Upload Audio', 'Use gTTS'],\n",
    "    description='Audio Source:'\n",
    ")\n",
    "\n",
    "upload_widget = widgets.FileUpload(accept='.mp3,.wav', multiple=False)\n",
    "gtts_text = widgets.Text(placeholder='Enter text for Text to Speech', description='TTS:')\n",
    "submit_button = widgets.Button(description='Submit')\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to handle the display of widgets based on selection\n",
    "def on_audio_source_change(change):\n",
    "    if change['new'] == 'Upload Audio':\n",
    "        gtts_text.layout.display = 'none'\n",
    "        upload_widget.layout.display = 'block'\n",
    "    else:\n",
    "        upload_widget.layout.display = 'none'\n",
    "        gtts_text.layout.display = 'block'\n",
    "\n",
    "audio_source.observe(on_audio_source_change, names='value')\n",
    "\n",
    "# Function to handle submit button click\n",
    "def on_submit_click(b):\n",
    "    clear_output(wait=True)\n",
    "    with output:\n",
    "        if audio_source.value == 'Upload Audio':\n",
    "            if upload_widget.value:\n",
    "                try:\n",
    "                    # Print type and content of the upload_widget value\n",
    "                    print(\"Type of upload_widget.value:\", type(upload_widget.value))\n",
    "                    print(\"Content of upload_widget.value:\", upload_widget.value)\n",
    "\n",
    "                    # Handle tuple data\n",
    "                    if isinstance(upload_widget.value, tuple):\n",
    "                        uploaded_file = upload_widget.value[0]\n",
    "                    else:\n",
    "                        uploaded_file = list(upload_widget.value.values())[0]\n",
    "                    \n",
    "                    file_content = uploaded_file['content']\n",
    "                    \n",
    "                    with open('input_audio.wav', 'wb') as f:\n",
    "                        f.write(file_content)\n",
    "                    \n",
    "                    print(\"Uploaded file saved as 'input_audio.wav'\")\n",
    "                    display(Audio('input_audio.wav'))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error saving uploaded file: {e}\")\n",
    "            else:\n",
    "                print(\"No file uploaded.\")\n",
    "        else:\n",
    "            if gtts_text.value:\n",
    "                try:\n",
    "                    tts = gTTS(gtts_text.value)\n",
    "                    tts.save(\"input_audio.wav\")\n",
    "                    print(\"gTTS audio saved as 'input_audio.wav'\")\n",
    "                    display(Audio('input_audio.wav'))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating gTTS audio: {e}\")\n",
    "            else:\n",
    "                print(\"No text entered for gTTS.\")\n",
    "\n",
    "submit_button.on_click(on_submit_click)\n",
    "\n",
    "# Set initial state of widgets\n",
    "on_audio_source_change({'new': audio_source.value})\n",
    "\n",
    "# Display all widgets\n",
    "display(audio_source, upload_widget, gtts_text, submit_button, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess Output:\n",
      " Using cuda for inference.\n",
      "Reading video frames...\n",
      "Number of frames available for inference: 75\n",
      "(80, 493)\n",
      "Length of mel chunks: 151\n",
      "Load checkpoint from: Wav2Lip\\checkpoints\\wav2lip_gan.pth\n",
      "Model loaded\n",
      "\n",
      "Subprocess Error (if any):\n",
      " d:\\studentinfo\\test1\\project\\Wav2Lip\\audio.py:100: FutureWarning: Pass sr=16000, n_fft=800 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.filters.mel(hp.sample_rate, hp.n_fft, n_mels=hp.num_mels,\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      " 20%|â–ˆâ–ˆ        | 1/5 [01:38<06:33, 98.31s/it]\u001b[A\n",
      "\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:39<02:02, 40.91s/it]\u001b[A\n",
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:39<00:45, 22.53s/it]\u001b[A\n",
      "\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [01:40<00:13, 13.90s/it]\u001b[A\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:41<00:00,  9.31s/it]\u001b[A\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:41<00:00, 20.31s/it]\n",
      "\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [01:53<01:53, 113.38s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:56<00:00, 48.28s/it] \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:56<00:00, 58.05s/it]\n",
      "ffmpeg version 7.0.2-essentials_build-www.gyan.dev Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with gcc 13.2.0 (Rev5, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-zlib --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-sdl2 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxvid --enable-libaom --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libgme --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libtheora --enable-libvo-amrwbenc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-librubberband\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "[aist#0:0/pcm_s16le @ 000002cbb437c280] Guessed Channel Layout: mono\n",
      "Input #0, wav, from 'input_audio.wav':\n",
      "  Duration: 00:00:06.15, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, mono, s16, 384 kb/s\n",
      "Input #1, avi, from 'temp/result.avi':\n",
      "  Metadata:\n",
      "    software        : Lavf58.76.100\n",
      "  Duration: 00:00:06.04, start: 0.000000, bitrate: 123 kb/s\n",
      "  Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 180x144 [SAR 1:1 DAR 5:4], 112 kb/s, 25 fps, 25 tbr, 25 tbn\n",
      "Stream mapping:\n",
      "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 000002cbb441ec00] -qscale is ignored, -crf is recommended.\n",
      "[libx264 @ 000002cbb441ec00] using SAR=1/1\n",
      "[libx264 @ 000002cbb441ec00] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 000002cbb441ec00] profile High, level 1.1, 4:2:0, 8-bit\n",
      "[libx264 @ 000002cbb441ec00] 264 - core 164 r3191 4613ac3 - H.264/MPEG-4 AVC codec - Copyleft 2003-2024 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=4 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'Wav2Lip\\results\\lip_synced_video.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 180x144 [SAR 1:1 DAR 5:4], q=2-31, 25 fps, 12800 tbn\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.3.100 libx264\n",
      "      Side data:\n",
      "        cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 24000 Hz, mono, fltp, 69 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.3.100 aac\n",
      "[out#0/mp4 @ 000002cbb43b9140] video:39KiB audio:60KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 4.260949%\n",
      "frame=  151 fps=0.0 q=-1.0 Lsize=     103KiB time=00:00:05.96 bitrate= 141.8kbits/s speed=25.8x    \n",
      "[libx264 @ 000002cbb441ec00] frame I:1     Avg QP:20.66  size:  2916\n",
      "[libx264 @ 000002cbb441ec00] frame P:134   Avg QP:21.61  size:   264\n",
      "[libx264 @ 000002cbb441ec00] frame B:16    Avg QP:27.42  size:    54\n",
      "[libx264 @ 000002cbb441ec00] consecutive B-frames: 80.8% 13.2%  6.0%  0.0%\n",
      "[libx264 @ 000002cbb441ec00] mb I  I16..4: 25.9% 69.4%  4.6%\n",
      "[libx264 @ 000002cbb441ec00] mb P  I16..4:  1.5%  2.5%  0.0%  P16..4: 25.3%  7.2%  4.9%  0.0%  0.0%    skip:58.6%\n",
      "[libx264 @ 000002cbb441ec00] mb B  I16..4:  0.2%  0.4%  0.0%  B16..8: 24.9%  0.5%  0.0%  direct: 0.1%  skip:73.9%  L0:48.9% L1:49.8% BI: 1.4%\n",
      "[libx264 @ 000002cbb441ec00] 8x8 transform intra:63.9% inter:70.9%\n",
      "[libx264 @ 000002cbb441ec00] coded y,uvDC,uvAC intra: 43.4% 84.3% 11.4% inter: 8.3% 15.4% 2.2%\n",
      "[libx264 @ 000002cbb441ec00] i16 v,h,dc,p: 22% 35% 20% 23%\n",
      "[libx264 @ 000002cbb441ec00] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 12% 46% 32%  4%  1%  1%  1%  1%  2%\n",
      "[libx264 @ 000002cbb441ec00] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 34% 16%  9%  4%  4% 10%  2% 10% 11%\n",
      "[libx264 @ 000002cbb441ec00] i8c dc,h,v,p: 43% 25% 26%  6%\n",
      "[libx264 @ 000002cbb441ec00] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 000002cbb441ec00] ref P L0: 77.1%  8.9%  9.4%  4.5%\n",
      "[libx264 @ 000002cbb441ec00] ref B L0: 88.0% 11.5%  0.5%\n",
      "[libx264 @ 000002cbb441ec00] kb/s:51.92\n",
      "[aac @ 000002cbb43ed800] Qavg: 525.038\n",
      "\n",
      "Lip-synced video generated successfully: Wav2Lip\\results\\lip_synced_video.mp4\n",
      "Frames per second (FPS) of the generated video: 25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Define file paths (assuming they are uploaded to the working directory)\n",
    "video_path = \"input_video.mp4\"  # Change this if your video file has a different name\n",
    "audio_path = \"input_audio.wav\"  # Change this if your audio file has a different name\n",
    "result_dir = \"Wav2Lip\\\\results\"\n",
    "result_path = os.path.join(result_dir, \"lip_synced_video.mp4\")\n",
    "\n",
    "# Ensure the results directory exists\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "# Run the Wav2Lip script\n",
    "try:\n",
    "    process = subprocess.run(\n",
    "        [\n",
    "            \"python\", \"Wav2Lip\\\\inference.py\",\n",
    "            \"--checkpoint_path\", \"Wav2Lip\\\\checkpoints\\\\wav2lip_gan.pth\",\n",
    "            \"--face\", video_path,\n",
    "            \"--audio\", audio_path,\n",
    "            \"--outfile\", result_path,\n",
    "            \"--resize_factor\", \"2\"  # Change this to 0 if you have a high GPU\n",
    "        ],\n",
    "        capture_output=True, text=True, check=True\n",
    "    )\n",
    "    print(\"Subprocess Output:\\n\", process.stdout)\n",
    "    print(\"Subprocess Error (if any):\\n\", process.stderr)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    # Capture the error output\n",
    "    error_message = f\"Subprocess failed with exit code {e.returncode}\\n\"\n",
    "    error_message += f\"Output: {e.stdout}\\n\"\n",
    "    error_message += f\"Error: {e.stderr}\\n\"\n",
    "    print(error_message)\n",
    "\n",
    "# Check if the output file exists\n",
    "if os.path.exists(result_path):\n",
    "    print(f\"Lip-synced video generated successfully: {result_path}\")\n",
    "\n",
    "    # Get FPS of the generated video using ffprobe\n",
    "    try:\n",
    "        ffprobe_command = [\n",
    "            \"ffprobe\", \"-v\", \"error\", \"-select_streams\", \"v:0\", \"-show_entries\", \"stream=r_frame_rate\",\n",
    "            \"-of\", \"default=noprint_wrappers=1:nokey=1\", result_path\n",
    "        ]\n",
    "        fps_process = subprocess.run(\n",
    "            ffprobe_command, capture_output=True, text=True, check=True\n",
    "        )\n",
    "        fps_fraction = fps_process.stdout.strip()\n",
    "\n",
    "        # Convert FPS to integer if it's in fractional form\n",
    "        if '/' in fps_fraction:\n",
    "            numerator, denominator = map(int, fps_fraction.split('/'))\n",
    "            fps = numerator // denominator  # Use integer division for FPS\n",
    "        else:\n",
    "            fps = int(fps_fraction)\n",
    "\n",
    "        print(f\"Frames per second (FPS) of the generated video: {fps}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to get FPS of the video: {e}\")\n",
    "else:\n",
    "    print(\"Error: The lip-synced video was not generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch has access to a GPU!\n",
      "Quadro M1200\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"PyTorch has access to a GPU!\")\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"PyTorch is using CPU only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import base64\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from gfpgan.utils import GFPGANer\n",
    "from realesrgan.utils import RealESRGANer\n",
    "from basicsr.archs.srvgg_arch import SRVGGNetCompact\n",
    "from IPython.display import display\n",
    "import os\n",
    "import requests\n",
    "from diffusers import DiffusionPipeline, StableDiffusionXLImg2ImgPipeline \n",
    "from torchvision.transforms import ToTensor, Normalize, ConvertImageDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "realesr-general-x4v3.pth already exists. Skipping download.\n",
      "GFPGANv1.4.pth already exists. Skipping download.\n",
      "RestoreFormer.pth already exists. Skipping download.\n",
      "CodeFormer.pth already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "# URLs for the different model weights\n",
    "model_urls = {\n",
    "    'realesr-general-x4v3.pth': \"https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-general-x4v3.pth\",\n",
    "    'GFPGANv1.4.pth': \"https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth\",\n",
    "    'RestoreFormer.pth': \"https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/RestoreFormer.pth\",\n",
    "    'CodeFormer.pth': \"https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/CodeFormer.pth\",\n",
    "}\n",
    "\n",
    "# Create a directory for the weights if it doesn't exist\n",
    "os.makedirs('weights', exist_ok=True)\n",
    "\n",
    "# This function downloads a file from a given URL and saves it with the specified filename.\n",
    "def download_file(url, filename):\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(filename, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                f.write(chunk)\n",
    "        print(f\"Downloaded {filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to download {filename}. Status code: {response.status_code}\")\n",
    "\n",
    "\n",
    "for filename, url in model_urls.items():\n",
    "    file_path = os.path.join('weights', filename)\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        download_file(url, file_path)\n",
    "    else:\n",
    "        print(f\"{filename} already exists. Skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CodeFormer.pth', 'detection_Resnet50_Final.pth', 'GFPGANv1.4.pth', 'realesr-general-x4v3.pth', 'RestoreFormer.pth']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('weights'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "realesrgan_model_path = 'weights/realesr-general-x4v3.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RealESRGAN\n",
    "sr_model = SRVGGNetCompact(num_in_ch=3, num_out_ch=3, num_feat=64, num_conv=32, upscale=4, act_type='prelu')\n",
    "realesrganer = RealESRGANer(scale=4, model_path=realesrgan_model_path, model=sr_model, tile=0, tile_pad=10, pre_pad=0, half=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GFPGAN model\n",
    "gfpgan_model_path = 'weights/GFPGANv1.4.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to upscale image with RealESRGAN\n",
    "def upscale_image(image_path, output_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    # Upscale the image with RealESRGAN\n",
    "    output, _ = realesrganer.enhance(img, outscale=4)\n",
    "    cv2.imwrite(output_path, output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GFPGAN\n",
    "face_enhancer = GFPGANer(model_path=gfpgan_model_path, upscale=2, arch='clean', channel_multiplier=2, bg_upsampler=realesrganer)\n",
    "# change the upscale to 4 or 10 if you have High GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to enhance image with GFPGAN\n",
    "def enhance_faces(image_path, output_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    # Enhance faces with GFPGAN\n",
    "    _, _, img_enhanced = face_enhancer.enhance(img, has_aligned=False, only_center_face=False, paste_back=True)\n",
    "    cv2.imwrite(output_path, img_enhanced)\n",
    "    return img_enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_frames(video_path, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    for i in range(frame_count):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imwrite(os.path.join(output_dir, f\"frame_{i:04d}.png\"), frame)\n",
    "    cap.release()\n",
    "\n",
    "video_path = \"D:\\\\studentinfo\\\\test1\\\\project\\\\Wav2Lip\\\\results\\\\lip_synced_video.mp4\"\n",
    "output_dir = \"D:\\\\studentinfo\\\\test1\\\\project\\\\frames\"\n",
    "extract_frames(video_path, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_frame_dir = \"enhanced_frames\"\n",
    "os.makedirs(enhanced_frame_dir, exist_ok=True)\n",
    "\n",
    "for frame in os.listdir(output_dir):\n",
    "    frame_path = os.path.join(output_dir, frame)\n",
    "    enhanced_frame_path = os.path.join(enhanced_frame_dir, frame)\n",
    "    enhanced_image = enhance_faces(frame_path, enhanced_frame_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     video\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m     14\u001b[0m output_video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menhanced_lip_synced_video.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mreassemble_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43menhanced_frame_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m, in \u001b[0;36mreassemble_video\u001b[1;34m(frame_dir, output_video_path, fps)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreassemble_video\u001b[39m(frame_dir, output_video_path, fps\u001b[38;5;241m=\u001b[39mfps):\n\u001b[0;32m      2\u001b[0m     frame_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(frame_dir, img) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(frame_dir)])\n\u001b[1;32m----> 3\u001b[0m     frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[43mframe_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      4\u001b[0m     height, width, layers \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m      6\u001b[0m     video \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoWriter(output_video_path, cv2\u001b[38;5;241m.\u001b[39mVideoWriter_fourcc(\u001b[38;5;241m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmp4v\u001b[39m\u001b[38;5;124m'\u001b[39m), fps, (width, height))\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def reassemble_video(frame_dir, output_video_path, fps=fps):\n",
    "    frame_list = sorted([os.path.join(frame_dir, img) for img in os.listdir(frame_dir)])\n",
    "    frame = cv2.imread(frame_list[0])\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    video = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "    for frame_path in frame_list:\n",
    "        frame = cv2.imread(frame_path)\n",
    "        video.write(frame)\n",
    "\n",
    "    video.release()\n",
    "\n",
    "output_video_path = \"enhanced_lip_synced_video.mp4\"\n",
    "reassemble_video(enhanced_frame_dir, output_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "MoviePy error: the file enhanced_lip_synced_video.mp4 could not be found!\nPlease check that you entered the correct path.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m audio_path \u001b[38;5;241m=\u001b[39m audio_path\n\u001b[0;32m     10\u001b[0m final_video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_video.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 11\u001b[0m \u001b[43madd_audio_to_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_video_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m, in \u001b[0;36madd_audio_to_video\u001b[1;34m(video_path, audio_path, output_path)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_audio_to_video\u001b[39m(video_path, audio_path, output_path):\n\u001b[1;32m----> 4\u001b[0m     video \u001b[38;5;241m=\u001b[39m \u001b[43mVideoFileClip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     audio \u001b[38;5;241m=\u001b[39m AudioFileClip(audio_path)\n\u001b[0;32m      6\u001b[0m     video \u001b[38;5;241m=\u001b[39m video\u001b[38;5;241m.\u001b[39mset_audio(audio)\n",
      "File \u001b[1;32md:\\studentinfo\\project\\final_year\\finalyear\\lib\\site-packages\\moviepy\\video\\io\\VideoFileClip.py:88\u001b[0m, in \u001b[0;36mVideoFileClip.__init__\u001b[1;34m(self, filename, has_mask, audio, audio_buffersize, target_resolution, resize_algorithm, audio_fps, audio_nbytes, verbose, fps_source)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Make a reader\u001b[39;00m\n\u001b[0;32m     87\u001b[0m pix_fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgba\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_mask \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb24\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader \u001b[38;5;241m=\u001b[39m \u001b[43mFFMPEG_VideoReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpix_fmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpix_fmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mtarget_resolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_resolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mresize_algo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresize_algorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mfps_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfps_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Make some of the reader's attributes accessible from the clip\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader\u001b[38;5;241m.\u001b[39mduration\n",
      "File \u001b[1;32md:\\studentinfo\\project\\final_year\\finalyear\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:35\u001b[0m, in \u001b[0;36mFFMPEG_VideoReader.__init__\u001b[1;34m(self, filename, print_infos, bufsize, pix_fmt, check_duration, target_resolution, resize_algo, fps_source)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m infos \u001b[38;5;241m=\u001b[39m \u001b[43mffmpeg_parse_infos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_infos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_duration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mfps_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfps \u001b[38;5;241m=\u001b[39m infos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_fps\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m=\u001b[39m infos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32md:\\studentinfo\\project\\final_year\\finalyear\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:270\u001b[0m, in \u001b[0;36mffmpeg_parse_infos\u001b[1;34m(filename, print_infos, check_duration, fps_source)\u001b[0m\n\u001b[0;32m    268\u001b[0m lines \u001b[38;5;241m=\u001b[39m infos\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m lines[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMoviePy error: the file \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m could not be found!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    271\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check that you entered the correct \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    272\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m%\u001b[39mfilename)\n\u001b[0;32m    274\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# get duration (in seconds)\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: MoviePy error: the file enhanced_lip_synced_video.mp4 could not be found!\nPlease check that you entered the correct path."
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "\n",
    "def add_audio_to_video(video_path, audio_path, output_path):\n",
    "    video = VideoFileClip(video_path)\n",
    "    audio = AudioFileClip(audio_path)\n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "\n",
    "audio_path = audio_path\n",
    "final_video_path = \"final_video.mp4\"\n",
    "add_audio_to_video(output_video_path, audio_path, final_video_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean all the mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder emptied successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "folder_path = 'enhanced_frames'  # Replace with your folder path\n",
    "files = glob.glob(os.path.join(folder_path, '*.jpg')) + glob.glob(os.path.join(folder_path, '*.png'))\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "folder_path = 'frames'  # Replace with your folder path\n",
    "files = glob.glob(os.path.join(folder_path, '*.jpg')) + glob.glob(os.path.join(folder_path, '*.png'))\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "print(\"Folder emptied successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (project)",
   "language": "python",
   "name": "final_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
